{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ENAS_OG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9A-o4b8e15i"
      },
      "source": [
        "Note that this code was adapted from the pytorch macro search implementation of ENAS, credits to https://github.com/MengTianjian/enas-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DPofOr_uY65"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data.dataset import Subset\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.distributions.categorical import Categorical\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEHhOUVh0vsp"
      },
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LyE5LUh0woF"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ElG1A_L__ex"
      },
      "source": [
        "Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV1oC6tdAAZi"
      },
      "source": [
        "args = {\n",
        "    'description':'ENAS',\n",
        "    'search_for':'macro',\n",
        "    'data_path':'export/data/',\n",
        "    'output_filename':'ENAS',\n",
        "    'resume':'',\n",
        "    'batch_size':128,\n",
        "    'num_epochs':30,\n",
        "    'log_every':50,\n",
        "    'eval_every_epochs':1,\n",
        "    'seed':69,\n",
        "    'cutout':0,\n",
        "    'fixed_arc':False,\n",
        "    'child_num_layers':12,\n",
        "    'child_out_filters':36,\n",
        "    'child_grad_bound':5.0,\n",
        "    'child_l2_reg':0.00025,\n",
        "    'child_num_branches':3,\n",
        "    'child_keep_prob':0.9,\n",
        "    'child_lr_max':0.05,\n",
        "    'child_lr_min':0.0005,\n",
        "    'child_lr_T':10,\n",
        "    'controller_lstm_size':64,\n",
        "    'controller_lstm_num_layers':1,\n",
        "    'controller_entropy_weight':0.0001,\n",
        "    'controller_train_every':1,\n",
        "    'controller_num_aggregate':20,\n",
        "    'controller_train_steps':50,\n",
        "    'controller_lr':0.001,\n",
        "    'controller_tanh_constant':1.5,\n",
        "    'controller_op_tanh_reduce':2.5,\n",
        "    'controller_skip_target':0.4,\n",
        "    'controller_skip_weight':0.8,\n",
        "    'controller_bl_dec':0.99\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTP1BxNix2Ml"
      },
      "source": [
        "Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMbT-ZH55BQC"
      },
      "source": [
        "class Cutout(object):\n",
        "    \"\"\"Randomly mask out a patche from an image.\n",
        "    Args:\n",
        "        length (int): The length (in pixels) of each square patch.\n",
        "        p (float): The probability of cutout being applied.\n",
        "    \"\"\"\n",
        "    def __init__(self, length, p=0.5):\n",
        "        self.length = length\n",
        "        self.p = p\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (Tensor): Tensor image of size (C, H, W).\n",
        "        Returns:\n",
        "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
        "        \"\"\"\n",
        "\n",
        "        if np.random.rand() < self.p:\n",
        "\n",
        "            h = img.size(1)\n",
        "            w = img.size(2)\n",
        "\n",
        "            mask = np.ones((h, w), np.float32)\n",
        "\n",
        "            y = np.random.randint(h)\n",
        "            x = np.random.randint(w)\n",
        "\n",
        "            y1 = np.clip(y - self.length, 0, h)\n",
        "            y2 = np.clip(y + self.length, 0, h)\n",
        "            x1 = np.clip(x - self.length, 0, w)\n",
        "            x2 = np.clip(x + self.length, 0, w)\n",
        "\n",
        "            mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "            mask = torch.from_numpy(mask)\n",
        "            mask = mask.expand_as(img)\n",
        "            img = img * mask\n",
        "\n",
        "        return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGWsO9kj5B8a"
      },
      "source": [
        "# class Logger(object):\n",
        "#     def __init__(self, filename):\n",
        "#         self.terminal = sys.stdout\n",
        "#         self.log = open(filename, 'w')\n",
        "\n",
        "#     def write(self, message):\n",
        "#         self.terminal.write(message)\n",
        "#         self.log.write(message)\n",
        "#         self.log.flush()\n",
        "\n",
        "#     def flush(self):\n",
        "#         #this flush method is needed for python 3 compatibility.\n",
        "#         #this handles the flush command by doing nothing.\n",
        "#         #you might want to specify some extra behavior here.\n",
        "#         pass\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T56Pc-J6Ger"
      },
      "source": [
        "Controller"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJNnOhoi6F9V"
      },
      "source": [
        "class Controller(nn.Module):\n",
        "    '''\n",
        "    https://github.com/melodyguan/enas/blob/master/src/cifar10/general_controller.py\n",
        "    '''\n",
        "    def __init__(self,\n",
        "                 search_for=\"macro\",\n",
        "                 search_whole_channels=True,\n",
        "                 num_layers=12,\n",
        "                 num_branches=6,\n",
        "                 out_filters=36,\n",
        "                 lstm_size=32,\n",
        "                 lstm_num_layers=2,\n",
        "                 tanh_constant=1.5,\n",
        "                 temperature=None,\n",
        "                 skip_target=0.4,\n",
        "                 skip_weight=0.8):\n",
        "        super(Controller, self).__init__()\n",
        "\n",
        "        self.search_for = search_for\n",
        "        self.search_whole_channels = search_whole_channels\n",
        "        self.num_layers = num_layers\n",
        "        self.num_branches = num_branches\n",
        "        self.out_filters = out_filters\n",
        "\n",
        "        self.lstm_size = lstm_size\n",
        "        self.lstm_num_layers = lstm_num_layers\n",
        "        self.tanh_constant = tanh_constant\n",
        "        self.temperature = temperature\n",
        "\n",
        "        self.skip_target = skip_target\n",
        "        self.skip_weight = skip_weight\n",
        "\n",
        "        self._create_params()\n",
        "\n",
        "    def _create_params(self):\n",
        "        '''\n",
        "        https://github.com/melodyguan/enas/blob/master/src/cifar10/general_controller.py#L83\n",
        "        '''\n",
        "        self.w_lstm = nn.LSTM(input_size=self.lstm_size,\n",
        "                              hidden_size=self.lstm_size,\n",
        "                              num_layers=self.lstm_num_layers)\n",
        "\n",
        "        self.g_emb = nn.Embedding(1, self.lstm_size)  # Learn the starting input\n",
        "\n",
        "        if self.search_whole_channels:\n",
        "            self.w_emb = nn.Embedding(self.num_branches, self.lstm_size)\n",
        "            self.w_soft = nn.Linear(self.lstm_size, self.num_branches, bias=False)\n",
        "        else:\n",
        "            assert False, \"Not implemented error: search_whole_channels = False\"\n",
        "\n",
        "        self.w_attn_1 = nn.Linear(self.lstm_size, self.lstm_size, bias=False)\n",
        "        self.w_attn_2 = nn.Linear(self.lstm_size, self.lstm_size, bias=False)\n",
        "        self.v_attn = nn.Linear(self.lstm_size, 1, bias=False)\n",
        "\n",
        "        self._reset_params()\n",
        "\n",
        "    def _reset_params(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear) or isinstance(m, nn.Embedding):\n",
        "                nn.init.uniform_(m.weight, -0.1, 0.1)\n",
        "\n",
        "        nn.init.uniform_(self.w_lstm.weight_hh_l0, -0.1, 0.1)\n",
        "        nn.init.uniform_(self.w_lstm.weight_ih_l0, -0.1, 0.1)\n",
        "\n",
        "    def forward(self):\n",
        "        '''\n",
        "        https://github.com/melodyguan/enas/blob/master/src/cifar10/general_controller.py#L126\n",
        "        '''\n",
        "        h0 = None  # setting h0 to None will initialize LSTM state with 0s\n",
        "\n",
        "        anchors = []\n",
        "        anchors_w_1 = []\n",
        "\n",
        "        arc_seq = {}\n",
        "        entropys = []\n",
        "        log_probs = []\n",
        "        skip_count = []\n",
        "        skip_penaltys = []\n",
        "\n",
        "        inputs = self.g_emb.weight\n",
        "        skip_targets = torch.tensor([1.0 - self.skip_target, self.skip_target]).cuda()\n",
        "\n",
        "        for layer_id in range(self.num_layers):\n",
        "            if self.search_whole_channels:\n",
        "                inputs = inputs.unsqueeze(0)\n",
        "                output, hn = self.w_lstm(inputs, h0)\n",
        "                output = output.squeeze(0)\n",
        "                h0 = hn\n",
        "\n",
        "                logit = self.w_soft(output)\n",
        "                if self.temperature is not None:\n",
        "                    logit /= self.temperature\n",
        "                if self.tanh_constant is not None:\n",
        "                    logit = self.tanh_constant * torch.tanh(logit)\n",
        "\n",
        "                branch_id_dist = Categorical(logits=logit)\n",
        "                branch_id = branch_id_dist.sample()\n",
        "\n",
        "                arc_seq[str(layer_id)] = [branch_id]\n",
        "\n",
        "                log_prob = branch_id_dist.log_prob(branch_id)\n",
        "                log_probs.append(log_prob.view(-1))\n",
        "                entropy = branch_id_dist.entropy()\n",
        "                entropys.append(entropy.view(-1))\n",
        "\n",
        "                inputs = self.w_emb(branch_id)\n",
        "                inputs = inputs.unsqueeze(0)\n",
        "            else:\n",
        "                # https://github.com/melodyguan/enas/blob/master/src/cifar10/general_controller.py#L171\n",
        "                assert False, \"Not implemented error: search_whole_channels = False\"\n",
        "\n",
        "            output, hn = self.w_lstm(inputs, h0)\n",
        "            output = output.squeeze(0)\n",
        "\n",
        "            if layer_id > 0:\n",
        "                query = torch.cat(anchors_w_1, dim=0)\n",
        "                query = torch.tanh(query + self.w_attn_2(output))\n",
        "                query = self.v_attn(query)\n",
        "                logit = torch.cat([-query, query], dim=1)\n",
        "                if self.temperature is not None:\n",
        "                    logit /= self.temperature\n",
        "                if self.tanh_constant is not None:\n",
        "                    logit = self.tanh_constant * torch.tanh(logit)\n",
        "\n",
        "                skip_dist = Categorical(logits=logit)\n",
        "                skip = skip_dist.sample()\n",
        "                skip = skip.view(layer_id)\n",
        "\n",
        "                arc_seq[str(layer_id)].append(skip)\n",
        "\n",
        "                skip_prob = torch.sigmoid(logit)\n",
        "                kl = skip_prob * torch.log(skip_prob / skip_targets)\n",
        "                kl = torch.sum(kl)\n",
        "                skip_penaltys.append(kl)\n",
        "\n",
        "                log_prob = skip_dist.log_prob(skip)\n",
        "                log_prob = torch.sum(log_prob)\n",
        "                log_probs.append(log_prob.view(-1))\n",
        "\n",
        "                entropy = skip_dist.entropy()\n",
        "                entropy = torch.sum(entropy)\n",
        "                entropys.append(entropy.view(-1))\n",
        "\n",
        "                # Calculate average hidden state of all nodes that got skips\n",
        "                # and use it as input for next step\n",
        "                skip = skip.type(torch.float)\n",
        "                skip = skip.view(1, layer_id)\n",
        "                skip_count.append(torch.sum(skip))\n",
        "                inputs = torch.matmul(skip, torch.cat(anchors, dim=0))\n",
        "                inputs /= (1.0 + torch.sum(skip))\n",
        "\n",
        "            else:\n",
        "                inputs = self.g_emb.weight\n",
        "\n",
        "            anchors.append(output)\n",
        "            anchors_w_1.append(self.w_attn_1(output))\n",
        "\n",
        "        self.sample_arc = arc_seq\n",
        "\n",
        "        entropys = torch.cat(entropys)\n",
        "        self.sample_entropy = torch.sum(entropys)\n",
        "\n",
        "        log_probs = torch.cat(log_probs)\n",
        "        self.sample_log_prob = torch.sum(log_probs)\n",
        "\n",
        "        skip_count = torch.stack(skip_count)\n",
        "        self.skip_count = torch.sum(skip_count)\n",
        "\n",
        "        skip_penaltys = torch.stack(skip_penaltys)\n",
        "        self.skip_penaltys = torch.mean(skip_penaltys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VruBMpRx6iTj"
      },
      "source": [
        "Child"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRTqpb_i6juS"
      },
      "source": [
        "class FactorizedReduction(nn.Module):\n",
        "    '''\n",
        "    Reduce both spatial dimensions (width and height) by a factor of 2, and \n",
        "    potentially to change the number of output filters\n",
        "    https://github.com/melodyguan/enas/blob/master/src/cifar10/general_child.py#L129\n",
        "    '''\n",
        "\n",
        "    def __init__(self, in_planes, out_planes, stride=2):\n",
        "        super(FactorizedReduction, self).__init__()\n",
        "\n",
        "        assert out_planes % 2 == 0, (\n",
        "        \"Need even number of filters when using this factorized reduction.\")\n",
        "\n",
        "        self.in_planes = in_planes\n",
        "        self.out_planes = out_planes\n",
        "        self.stride = stride\n",
        "\n",
        "        if stride == 1:\n",
        "            self.fr = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(out_planes, track_running_stats=False))\n",
        "        else:\n",
        "            self.path1 = nn.Sequential(\n",
        "                nn.AvgPool2d(1, stride=stride),\n",
        "                nn.Conv2d(in_planes, out_planes // 2, kernel_size=1, bias=False))\n",
        "\n",
        "            self.path2 = nn.Sequential(\n",
        "                nn.AvgPool2d(1, stride=stride),\n",
        "                nn.Conv2d(in_planes, out_planes // 2, kernel_size=1, bias=False))\n",
        "            self.bn = nn.BatchNorm2d(out_planes, track_running_stats=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.stride == 1:\n",
        "            return self.fr(x)\n",
        "        else:\n",
        "            path1 = self.path1(x)\n",
        "\n",
        "            # pad the right and the bottom, then crop to include those pixels\n",
        "            path2 = F.pad(x, pad=(0, 1, 0, 1), mode='constant', value=0.)\n",
        "            path2 = path2[:, :, 1:, 1:]\n",
        "            path2 = self.path2(path2)\n",
        "\n",
        "            out = torch.cat([path1, path2], dim=1)\n",
        "            out = self.bn(out)\n",
        "            return out\n",
        "\n",
        "class ENASLayer(nn.Module):\n",
        "    '''\n",
        "    https://github.com/melodyguan/enas/blob/master/src/cifar10/general_child.py#L245\n",
        "    '''\n",
        "    def __init__(self, layer_id, in_planes, out_planes):\n",
        "        super(ENASLayer, self).__init__()\n",
        "\n",
        "        self.layer_id = layer_id\n",
        "        self.in_planes = in_planes\n",
        "        self.out_planes = out_planes\n",
        "#TO POISTON THE SEARCH SPACE TAKE OUT VARIOUS COMBINATIONS OF THE FOLLOWING BRANCHES AND MAKE THE CHANGES TO THE FORWARD FUNCTION BELLOW! \n",
        "#WE SUGGEST TAKING OUT 3 BY 3 CONVOLUTIOJNS AND ONE OF THE POOLING BRANCHES AS AN APPROPRIATE POISONING\n",
        "        self.branch_0 = ConvBranch(in_planes, out_planes, kernel_size=3)\n",
        "        self.branch_1 = ConvBranch(in_planes, out_planes, kernel_size=3, separable=True)\n",
        "        self.branch_2 = ConvBranch(in_planes, out_planes, kernel_size=5)\n",
        "        self.branch_3 = ConvBranch(in_planes, out_planes, kernel_size=5, separable=True)\n",
        "        self.branch_4 = PoolBranch(in_planes, out_planes, 'avg')\n",
        "        self.branch_5 = PoolBranch(in_planes, out_planes, 'max')\n",
        "\n",
        "        self.bn = nn.BatchNorm2d(out_planes, track_running_stats=False)\n",
        "\n",
        "    def forward(self, x, prev_layers, sample_arc):\n",
        "        layer_type = sample_arc[0]\n",
        "        if self.layer_id > 0:\n",
        "            skip_indices = sample_arc[1]\n",
        "        else:\n",
        "            skip_indices = []\n",
        "#CHANGE THIS BASED ON THE POISONING MENTIONED ABOVE  \n",
        "        if layer_type == 0:\n",
        "            out = self.branch_0(x)\n",
        "        elif layer_type == 1:\n",
        "            out = self.branch_1(x)\n",
        "        elif layer_type == 2:\n",
        "            out = self.branch_2(x)\n",
        "        elif layer_type == 3:\n",
        "            out = self.branch_3(x)\n",
        "        elif layer_type == 4:\n",
        "            out = self.branch_4(x)\n",
        "        elif layer_type == 5:\n",
        "            out = self.branch_5(x)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown layer_type {}\".format(layer_type))\n",
        "\n",
        "        for i, skip in enumerate(skip_indices):\n",
        "            if skip == 1:\n",
        "                out += prev_layers[i]\n",
        "\n",
        "        out = self.bn(out)\n",
        "        return out\n",
        "\n",
        "class FixedLayer(nn.Module):\n",
        "    '''\n",
        "    https://github.com/melodyguan/enas/blob/master/src/cifar10/general_child.py#L245\n",
        "    '''\n",
        "    def __init__(self, layer_id, in_planes, out_planes, sample_arc):\n",
        "        super(FixedLayer, self).__init__()\n",
        "\n",
        "        self.layer_id = layer_id\n",
        "        self.in_planes = in_planes\n",
        "        self.out_planes = out_planes\n",
        "        self.sample_arc = sample_arc\n",
        "\n",
        "        self.layer_type = sample_arc[0]\n",
        "        if self.layer_id > 0:\n",
        "            self.skip_indices = sample_arc[1]\n",
        "        else:\n",
        "            self.skip_indices = torch.zeros(1)\n",
        "\n",
        "        \n",
        "        if self.layer_type == 0:\n",
        "            self.branch = ConvBranch(in_planes, out_planes, kernel_size=5)\n",
        "        elif self.layer_type == 1:\n",
        "            self.branch = ConvBranch(in_planes, out_planes, kernel_size=5, separable=True)\n",
        "        elif self.layer_type == 2:\n",
        "            self.branch = PoolBranch(in_planes, out_planes, 'avg')\n",
        "      \n",
        "        else:\n",
        "            raise ValueError(\"Unknown layer_type {}\".format(self.layer_type))\n",
        "\n",
        "        # Use concatentation instead of addition in the fixed layer for some reason\n",
        "        in_planes = int((torch.sum(self.skip_indices).item() + 1) * in_planes)\n",
        "        self.dim_reduc = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(out_planes, track_running_stats=False))\n",
        "\n",
        "    def forward(self, x, prev_layers, sample_arc):\n",
        "        out = self.branch(x)\n",
        "\n",
        "        res_layers = []\n",
        "        for i, skip in enumerate(self.skip_indices):\n",
        "            if skip == 1:\n",
        "                res_layers.append(prev_layers[i])\n",
        "        prev = res_layers + [out]\n",
        "        prev = torch.cat(prev, dim=1)\n",
        "\n",
        "        out = self.dim_reduc(prev)\n",
        "        return out\n",
        "\n",
        "class SeparableConv(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, bias):\n",
        "        super(SeparableConv, self).__init__()\n",
        "        padding = (kernel_size - 1) // 2\n",
        "        self.depthwise = nn.Conv2d(in_planes, in_planes, kernel_size=kernel_size,\n",
        "                                   padding=padding, groups=in_planes, bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.depthwise(x)\n",
        "        out = self.pointwise(out)\n",
        "        return out\n",
        "\n",
        "class ConvBranch(nn.Module):\n",
        "    '''\n",
        "    https://github.com/melodyguan/enas/blob/master/src/cifar10/general_child.py#L483\n",
        "    '''\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, separable=False):\n",
        "        super(ConvBranch, self).__init__()\n",
        "        assert kernel_size in [3,5], \"Kernel size must be either 3 or 5\"\n",
        "\n",
        "        self.in_planes = in_planes\n",
        "        self.out_planes = out_planes\n",
        "        self.kernel_size = kernel_size\n",
        "        self.separable = separable\n",
        "\n",
        "        self.inp_conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_planes, track_running_stats=False),\n",
        "            nn.ReLU())\n",
        "\n",
        "        if separable:\n",
        "            self.out_conv = nn.Sequential(\n",
        "                SeparableConv(in_planes, out_planes, kernel_size=kernel_size, bias=False),\n",
        "                nn.BatchNorm2d(out_planes, track_running_stats=False),\n",
        "                nn.ReLU())\n",
        "        else:\n",
        "            padding = (kernel_size - 1) // 2\n",
        "            self.out_conv = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size,\n",
        "                          padding=padding, bias=False),\n",
        "                nn.BatchNorm2d(out_planes, track_running_stats=False),\n",
        "                nn.ReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.inp_conv1(x)\n",
        "        out = self.out_conv(out)\n",
        "        return out\n",
        "\n",
        "class PoolBranch(nn.Module):\n",
        "    '''\n",
        "    https://github.com/melodyguan/enas/blob/master/src/cifar10/general_child.py#L546\n",
        "    '''\n",
        "    def __init__(self, in_planes, out_planes, avg_or_max):\n",
        "        super(PoolBranch, self).__init__()\n",
        "\n",
        "        self.in_planes = in_planes\n",
        "        self.out_planes = out_planes\n",
        "        self.avg_or_max = avg_or_max\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, out_planes, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(out_planes, track_running_stats=False),\n",
        "            nn.ReLU())\n",
        "\n",
        "        if avg_or_max == 'avg':\n",
        "            self.pool = torch.nn.AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        elif avg_or_max == 'max':\n",
        "            self.pool = torch.nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        else:\n",
        "            raise ValueError(\"Unknown pool {}\".format(avg_or_max))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.pool(out)\n",
        "        return out\n",
        "\n",
        "class SharedCNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_layers=12,\n",
        "                 num_branches=6,\n",
        "                 out_filters=24,\n",
        "                 keep_prob=1.0,\n",
        "                 fixed_arc=None\n",
        "                 ):\n",
        "        super(SharedCNN, self).__init__()\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.num_branches = num_branches\n",
        "        self.out_filters = out_filters\n",
        "        self.keep_prob = keep_prob\n",
        "        self.fixed_arc = fixed_arc\n",
        "\n",
        "        pool_distance = self.num_layers // 3\n",
        "        self.pool_layers = [pool_distance - 1, 2 * pool_distance - 1]\n",
        "\n",
        "        self.stem_conv = nn.Sequential(\n",
        "            nn.Conv2d(3, out_filters, kernel_size=3, padding=1, bias=False),\n",
        "            # nn.Conv2d(1, out_filters, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_filters, track_running_stats=False))\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "        self.pooled_layers = nn.ModuleList([])\n",
        "\n",
        "        for layer_id in range(self.num_layers):\n",
        "            if self.fixed_arc is None:\n",
        "                layer = ENASLayer(layer_id, self.out_filters, self.out_filters)\n",
        "            else:\n",
        "                layer = FixedLayer(layer_id, self.out_filters, self.out_filters, self.fixed_arc[str(layer_id)])\n",
        "            self.layers.append(layer)\n",
        "\n",
        "            if layer_id in self.pool_layers:\n",
        "                for i in range(len(self.layers)):\n",
        "                    if self.fixed_arc is None:\n",
        "                        self.pooled_layers.append(FactorizedReduction(self.out_filters, self.out_filters))\n",
        "                    else:\n",
        "                        self.pooled_layers.append(FactorizedReduction(self.out_filters, self.out_filters * 2))\n",
        "                if self.fixed_arc is not None:\n",
        "                    self.out_filters *= 2\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(p=1. - self.keep_prob)\n",
        "        self.classify = nn.Linear(self.out_filters, 10)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "    def forward(self, x, sample_arc):\n",
        "\n",
        "        x = self.stem_conv(x)\n",
        "\n",
        "        prev_layers = []\n",
        "        pool_count = 0\n",
        "        for layer_id in range(self.num_layers):\n",
        "            x = self.layers[layer_id](x, prev_layers, sample_arc[str(layer_id)])\n",
        "            prev_layers.append(x)\n",
        "            if layer_id in self.pool_layers:\n",
        "                for i, prev_layer in enumerate(prev_layers):\n",
        "                    # Go through the outputs of all previous layers and downsample them\n",
        "                    prev_layers[i] = self.pooled_layers[pool_count](prev_layer)\n",
        "                    pool_count += 1\n",
        "                x = prev_layers[-1]\n",
        "\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.dropout(x)\n",
        "        out = self.classify(x)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS2tNgkd7LQb"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-wwWDx-7K_I"
      },
      "source": [
        "def train_shared_cnn(epoch,\n",
        "                     controller,\n",
        "                     shared_cnn,\n",
        "                     data_loaders,\n",
        "                     shared_cnn_optimizer,\n",
        "                     fixed_arc=None):\n",
        "    \"\"\"Train shared_cnn by sampling architectures from the controller.\n",
        "    Args:\n",
        "        epoch: Current epoch.\n",
        "        controller: Controller module that generates architectures to be trained.\n",
        "        shared_cnn: CNN that contains all possible architectures, with shared weights.\n",
        "        data_loaders: Dict containing data loaders.\n",
        "        shared_cnn_optimizer: Optimizer for the shared_cnn.\n",
        "        fixed_arc: Architecture to train, overrides the controller sample\n",
        "        ...\n",
        "    \n",
        "    Returns: Nothing.\n",
        "    \"\"\"\n",
        "\n",
        "    controller.eval()\n",
        "\n",
        "    if fixed_arc is None:\n",
        "        # Use a subset of the training set when searching for an arhcitecture\n",
        "        train_loader = data_loaders['train_subset']\n",
        "    else:\n",
        "        # Use the full training set when training a fixed architecture\n",
        "        train_loader = data_loaders['train_dataset']\n",
        "\n",
        "    train_acc_meter = AverageMeter()\n",
        "    loss_meter = AverageMeter()\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        start = time.time()\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        if fixed_arc is None:\n",
        "            with torch.no_grad():\n",
        "                controller()  # perform forward pass to generate a new architecture\n",
        "            sample_arc = controller.sample_arc\n",
        "        else:\n",
        "            sample_arc = fixed_arc\n",
        "\n",
        "        shared_cnn.zero_grad()\n",
        "        pred = shared_cnn(images, sample_arc)\n",
        "        loss = nn.CrossEntropyLoss()(pred, labels)\n",
        "        loss.backward()\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(shared_cnn.parameters(), args['child_grad_bound'])\n",
        "        shared_cnn_optimizer.step()\n",
        "\n",
        "        train_acc = torch.mean((torch.max(pred, 1)[1] == labels).type(torch.float))\n",
        "\n",
        "        train_acc_meter.update(train_acc.item())\n",
        "        loss_meter.update(loss.item())\n",
        "\n",
        "        end = time.time()\n",
        "\n",
        "        if (i) % args['log_every'] == 0:\n",
        "            learning_rate = shared_cnn_optimizer.param_groups[0]['lr']\n",
        "            display = 'epoch=' + str(epoch) + \\\n",
        "                      '\\tch_step=' + str(i) + \\\n",
        "                      '\\tloss=%.6f' % (loss_meter.val) + \\\n",
        "                      '\\tlr=%.4f' % (learning_rate) + \\\n",
        "                      '\\t|g|=%.4f' % (grad_norm.item()) + \\\n",
        "                      '\\tacc=%.4f' % (train_acc_meter.val) + \\\n",
        "                      '\\ttime=%.2fit/s' % (1. / (end - start))\n",
        "            print(display)\n",
        "\n",
        "    \n",
        "    # vis_win['shared_cnn_acc'] = vis.line(\n",
        "    #     X=np.array([epoch]),\n",
        "    #     Y=np.array([train_acc_meter.avg]),\n",
        "    #     win=vis_win['shared_cnn_acc'],\n",
        "    #     opts=dict(title='shared_cnn_acc', xlabel='Iteration', ylabel='Accuracy'),\n",
        "    #     update='append' if epoch > 0 else None)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(np.array([epoch]),\n",
        "             np.array([train_acc_meter.avg]),\n",
        "             'ro-',\n",
        "             label='Shared CNN Accuracy')\n",
        "    plt.plot(np.array([epoch]),\n",
        "             np.array([loss_meter.avg]),\n",
        "             'go-',\n",
        "             label='Shared CNN Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Shared CNN')\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.savefig(\"child_training_curve.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # vis_win['shared_cnn_loss'] = vis.line(\n",
        "    #     X=np.array([epoch]),\n",
        "    #     Y=np.array([loss_meter.avg]),\n",
        "    #     win=vis_win['shared_cnn_loss'],\n",
        "    #     opts=dict(title='shared_cnn_loss', xlabel='Iteration', ylabel='Loss'),\n",
        "    #     update='append' if epoch > 0 else None)\n",
        "\n",
        "    controller.train()\n",
        "\n",
        "def train_controller(epoch,\n",
        "                     controller,\n",
        "                     shared_cnn,\n",
        "                     data_loaders,\n",
        "                     controller_optimizer,\n",
        "                     baseline=None):\n",
        "    \"\"\"Train controller to optimizer validation accuracy using REINFORCE.\n",
        "    Args:\n",
        "        epoch: Current epoch.\n",
        "        controller: Controller module that generates architectures to be trained.\n",
        "        shared_cnn: CNN that contains all possible architectures, with shared weights.\n",
        "        data_loaders: Dict containing data loaders.\n",
        "        controller_optimizer: Optimizer for the controller.\n",
        "        baseline: The baseline score (i.e. average val_acc) from the previous epoch\n",
        "    \n",
        "    Returns: \n",
        "        baseline: The baseline score (i.e. average val_acc) for the current epoch\n",
        "    For more stable training we perform weight updates using the average of\n",
        "    many gradient estimates. controller_num_aggregate indicates how many samples\n",
        "    we want to average over (default = 20). By default PyTorch will sum gradients\n",
        "    each time .backward() is called (as long as an optimizer step is not taken),\n",
        "    so each iteration we divide the loss by controller_num_aggregate to get the \n",
        "    average.\n",
        "    https://github.com/melodyguan/enas/blob/master/src/cifar10/general_controller.py#L270\n",
        "    \"\"\"\n",
        "    print('Epoch ' + str(epoch) + ': Training controller')\n",
        "\n",
        "    shared_cnn.eval()\n",
        "    valid_loader = data_loaders['valid_subset']\n",
        "\n",
        "    reward_meter = AverageMeter()\n",
        "    baseline_meter = AverageMeter()\n",
        "    val_acc_meter = AverageMeter()\n",
        "    loss_meter = AverageMeter()\n",
        "\n",
        "    controller.zero_grad()\n",
        "    for i in range(args['controller_train_steps'] * args['controller_num_aggregate']):\n",
        "        start = time.time()\n",
        "        images, labels = next(iter(valid_loader))\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        controller()  # perform forward pass to generate a new architecture\n",
        "        sample_arc = controller.sample_arc\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = shared_cnn(images, sample_arc)\n",
        "        val_acc = torch.mean((torch.max(pred, 1)[1] == labels).type(torch.float))\n",
        "\n",
        "        # detach to make sure that gradients aren't backpropped through the reward\n",
        "        reward = torch.tensor(val_acc.detach())\n",
        "        reward += args['controller_entropy_weight'] * controller.sample_entropy\n",
        "\n",
        "        if baseline is None:\n",
        "            baseline = val_acc\n",
        "        else:\n",
        "            baseline -= (1 - args['controller_bl_dec']) * (baseline - reward)\n",
        "            # detach to make sure that gradients are not backpropped through the baseline\n",
        "            baseline = baseline.detach()\n",
        "\n",
        "        loss = -1 * controller.sample_log_prob * (reward - baseline)\n",
        "\n",
        "        if args['controller_skip_weight'] is not None:\n",
        "            loss += args['controller_skip_weight'] * controller.skip_penaltys\n",
        "\n",
        "        reward_meter.update(reward.item())\n",
        "        baseline_meter.update(baseline.item())\n",
        "        val_acc_meter.update(val_acc.item())\n",
        "        loss_meter.update(loss.item())\n",
        "\n",
        "        # Average gradient over controller_num_aggregate samples\n",
        "        loss = loss / args['controller_num_aggregate']\n",
        "\n",
        "        loss.backward(retain_graph=True)\n",
        "\n",
        "        end = time.time()\n",
        "\n",
        "        # Aggregate gradients for controller_num_aggregate iterationa, then update weights\n",
        "        if (i + 1) % args['controller_num_aggregate'] == 0:\n",
        "            grad_norm = torch.nn.utils.clip_grad_norm_(controller.parameters(), args['child_grad_bound'])\n",
        "            controller_optimizer.step()\n",
        "            controller.zero_grad()\n",
        "\n",
        "            if (i + 1) % (2 * args['controller_num_aggregate']) == 0:\n",
        "                learning_rate = controller_optimizer.param_groups[0]['lr']\n",
        "                display = 'ctrl_step=' + str(i // args['controller_num_aggregate']) + \\\n",
        "                          '\\tloss=%.3f' % (loss_meter.val) + \\\n",
        "                          '\\tent=%.2f' % (controller.sample_entropy.item()) + \\\n",
        "                          '\\tlr=%.4f' % (learning_rate) + \\\n",
        "                          '\\t|g|=%.4f' % (grad_norm.item()) + \\\n",
        "                          '\\tacc=%.4f' % (val_acc_meter.val) + \\\n",
        "                          '\\tbl=%.2f' % (baseline_meter.val) + \\\n",
        "                          '\\ttime=%.2fit/s' % (1. / (end - start))\n",
        "                print(display)\n",
        "      \n",
        "    plt.figure()\n",
        "    plt.plot(np.column_stack([epoch] * 2), \n",
        "             np.column_stack([reward_meter.avg, baseline_meter.avg]), \n",
        "             'go-',\n",
        "             label='Controller Reward')\n",
        "    \n",
        "    plt.plot(np.array([epoch]),\n",
        "             np.array([val_acc_meter.avg]),\n",
        "             'ro-',\n",
        "             label='Controller Accuracy')\n",
        "    \n",
        "    plt.plot(np.array([epoch]),\n",
        "             np.array([loss_meter.avg]),\n",
        "             'bo-',\n",
        "             label='Controller Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Controller')\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.savefig(\"controller_training_curve.png\")\n",
        "    plt.show()\n",
        "    \n",
        "    # vis_win['controller_reward'] = vis.line(\n",
        "    #     X=np.column_stack([epoch] * 2),\n",
        "    #     Y=np.column_stack([reward_meter.avg, baseline_meter.avg]),\n",
        "    #     win=vis_win['controller_reward'],\n",
        "    #     opts=dict(title='controller_reward', xlabel='Iteration', ylabel='Reward'),\n",
        "    #     update='append' if epoch > 0 else None)\n",
        "\n",
        "    # vis_win['controller_acc'] = vis.line(\n",
        "    #     X=np.array([epoch]),\n",
        "    #     Y=np.array([val_acc_meter.avg]),\n",
        "    #     win=vis_win['controller_acc'],\n",
        "    #     opts=dict(title='controller_acc', xlabel='Iteration', ylabel='Accuracy'),\n",
        "    #     update='append' if epoch > 0 else None)\n",
        "\n",
        "    # vis_win['controller_loss'] = vis.line(\n",
        "    #     X=np.array([epoch]),\n",
        "    #     Y=np.array([loss_meter.avg]),\n",
        "    #     win=vis_win['controller_loss'],\n",
        "    #     opts=dict(title='controller_loss', xlabel='Iteration', ylabel='Loss'),\n",
        "    #     update='append' if epoch > 0 else None)\n",
        "\n",
        "    shared_cnn.train()\n",
        "    return baseline\n",
        "\n",
        "def train_enas(start_epoch,\n",
        "               controller,\n",
        "               shared_cnn,\n",
        "               data_loaders,\n",
        "               shared_cnn_optimizer,\n",
        "               controller_optimizer,\n",
        "               shared_cnn_scheduler):\n",
        "    \"\"\"Perform architecture search by training a controller and shared_cnn.\n",
        "    Args:\n",
        "        start_epoch: Epoch to begin on.\n",
        "        controller: Controller module that generates architectures to be trained.\n",
        "        shared_cnn: CNN that contains all possible architectures, with shared weights.\n",
        "        data_loaders: Dict containing data loaders.\n",
        "        shared_cnn_optimizer: Optimizer for the shared_cnn.\n",
        "        controller_optimizer: Optimizer for the controller.\n",
        "        shared_cnn_scheduler: Learning rate schedular for shared_cnn_optimizer\n",
        "    \n",
        "    Returns: Nothing.\n",
        "    \"\"\"\n",
        "\n",
        "    baseline = None\n",
        "    for epoch in range(start_epoch, args['num_epochs']):\n",
        "\n",
        "        train_shared_cnn(epoch,\n",
        "                         controller,\n",
        "                         shared_cnn,\n",
        "                         data_loaders,\n",
        "                         shared_cnn_optimizer)\n",
        "\n",
        "        baseline = train_controller(epoch,\n",
        "                                    controller,\n",
        "                                    shared_cnn,\n",
        "                                    data_loaders,\n",
        "                                    controller_optimizer,\n",
        "                                    baseline)\n",
        "\n",
        "        if epoch % args['eval_every_epochs'] == 0:\n",
        "            evaluate_model(epoch, controller, shared_cnn, data_loaders)\n",
        "\n",
        "        # shared_cnn_scheduler.step(epoch)\n",
        "        shared_cnn_scheduler.step()\n",
        "\n",
        "        state = {'epoch': epoch + 1,\n",
        "                 'args': args,\n",
        "                 'shared_cnn_state_dict': shared_cnn.state_dict(),\n",
        "                 'controller_state_dict': controller.state_dict(),\n",
        "                 'shared_cnn_optimizer': shared_cnn_optimizer.state_dict(),\n",
        "                 'controller_optimizer': controller_optimizer.state_dict()}\n",
        "        filename = args['output_filename'] + '.pth.tar'\n",
        "        torch.save(state, filename)\n",
        "\n",
        "def train_fixed(start_epoch,\n",
        "                controller,\n",
        "                shared_cnn,\n",
        "                data_loaders):\n",
        "    \"\"\"Train a fixed cnn architecture.\n",
        "    Args:\n",
        "        start_epoch: Epoch to begin on.\n",
        "        controller: Controller module that generates architectures to be trained.\n",
        "        shared_cnn: CNN that contains all possible architectures, with shared weights.\n",
        "        data_loaders: Dict containing data loaders.\n",
        "    \n",
        "    Returns: Nothing.\n",
        "    Given a fully trained controller and shared_cnn, we sample many architectures,\n",
        "    and then train a new cnn from scratch using the best architecture we found. \n",
        "    We change the number of filters in the new cnn such that the final layer \n",
        "    has 512 channels.\n",
        "    \"\"\"\n",
        "\n",
        "    best_arc, best_val_acc = get_best_arc(controller, shared_cnn, data_loaders, n_samples=100, verbose=True)\n",
        "    print('Best architecture:')\n",
        "    print_arc(best_arc)\n",
        "    print('Validation accuracy: ' + str(best_val_acc))\n",
        "\n",
        "    fixed_cnn = SharedCNN(num_layers=args['child_num_layers'],\n",
        "                          num_branches=args['child_num_branches'],\n",
        "                          out_filters=512 // 4,  # args.child_out_filters\n",
        "                          keep_prob=args['child_keep_prob'],\n",
        "                          fixed_arc=best_arc)\n",
        "    fixed_cnn = fixed_cnn.cuda()\n",
        "\n",
        "    fixed_cnn_optimizer = torch.optim.SGD(params=fixed_cnn.parameters(),\n",
        "                                          lr=args['child_lr_max'],\n",
        "                                          momentum=0.9,\n",
        "                                          nesterov=True,\n",
        "                                          weight_decay=args['child_l2_reg'])\n",
        "\n",
        "    fixed_cnn_scheduler = CosineAnnealingLR(optimizer=fixed_cnn_optimizer,\n",
        "                                            T_max=args['child_lr_T'],\n",
        "                                            eta_min=args['child_lr_min'])\n",
        "\n",
        "    test_loader = data_loaders['test_dataset']\n",
        "\n",
        "    for epoch in range(args['num_epochs']):\n",
        "\n",
        "        train_shared_cnn(epoch,\n",
        "                         controller,  # not actually used in training the fixed_cnn\n",
        "                         fixed_cnn,\n",
        "                         data_loaders,\n",
        "                         fixed_cnn_optimizer,\n",
        "                         best_arc)\n",
        "\n",
        "        if epoch % args['eval_every_epochs'] == 0:\n",
        "            test_acc = get_eval_accuracy(test_loader, fixed_cnn, best_arc)\n",
        "            print('Epoch ' + str(epoch) + ': Eval')\n",
        "            print('test_accuracy: %.4f' % (test_acc))\n",
        "\n",
        "        fixed_cnn_scheduler.step()\n",
        "\n",
        "        state = {'epoch': epoch + 1,\n",
        "                 'args': args,\n",
        "                 'best_arc': best_arc,\n",
        "                 'fixed_cnn_state_dict': shared_cnn.state_dict(),\n",
        "                 'fixed_cnn_optimizer': fixed_cnn_optimizer.state_dict()}\n",
        "        filename = args['output_filename'] + '_fixed.pth.tar'\n",
        "        torch.save(state, filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haOdNc0K9d0s"
      },
      "source": [
        "Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgP3Fjzx9gCJ"
      },
      "source": [
        "def evaluate_model(epoch, controller, shared_cnn, data_loaders, n_samples=10):\n",
        "    \"\"\"Print the validation and test accuracy for a controller and shared_cnn.\n",
        "    Args:\n",
        "        epoch: Current epoch.\n",
        "        controller: Controller module that generates architectures to be trained.\n",
        "        shared_cnn: CNN that contains all possible architectures, with shared weights.\n",
        "        data_loaders: Dict containing data loaders.\n",
        "        n_samples: Number of architectures to test when looking for the best one.\n",
        "    \n",
        "    Returns: Nothing.\n",
        "    \"\"\"\n",
        "\n",
        "    controller.eval()\n",
        "    shared_cnn.eval()\n",
        "\n",
        "    print('Here are ' + str(n_samples) + ' architectures:')\n",
        "    best_arc, _ = get_best_arc(controller, shared_cnn, data_loaders, n_samples, verbose=True)\n",
        "\n",
        "    valid_loader = data_loaders['valid_subset']\n",
        "    test_loader = data_loaders['test_dataset']\n",
        "\n",
        "    valid_acc = get_eval_accuracy(valid_loader, shared_cnn, best_arc)\n",
        "    test_acc = get_eval_accuracy(test_loader, shared_cnn, best_arc)\n",
        "\n",
        "    print('Epoch ' + str(epoch) + ': Eval')\n",
        "    print('valid_accuracy: %.4f' % (valid_acc))\n",
        "    print('test_accuracy: %.4f' % (test_acc))\n",
        "\n",
        "    controller.train()\n",
        "    shared_cnn.train()\n",
        "\n",
        "def get_best_arc(controller, shared_cnn, data_loaders, n_samples=10, verbose=False):\n",
        "    \"\"\"Evaluate several architectures and return the best performing one.\n",
        "    Args:\n",
        "        controller: Controller module that generates architectures to be trained.\n",
        "        shared_cnn: CNN that contains all possible architectures, with shared weights.\n",
        "        data_loaders: Dict containing data loaders.\n",
        "        n_samples: Number of architectures to test when looking for the best one.\n",
        "        verbose: If True, display the architecture and resulting validation accuracy.\n",
        "    \n",
        "    Returns:\n",
        "        best_arc: The best performing architecture.\n",
        "        best_vall_acc: Accuracy achieved on the best performing architecture.\n",
        "    All architectures are evaluated on the same minibatch from the validation set.\n",
        "    \"\"\"\n",
        "\n",
        "    controller.eval()\n",
        "    shared_cnn.eval()\n",
        "\n",
        "    valid_loader = data_loaders['valid_subset']\n",
        "\n",
        "    images, labels = next(iter(valid_loader))\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    arcs = []\n",
        "    val_accs = []\n",
        "    for i in range(n_samples):\n",
        "        with torch.no_grad():\n",
        "            controller()  # perform forward pass to generate a new architecture\n",
        "        sample_arc = controller.sample_arc\n",
        "        arcs.append(sample_arc)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = shared_cnn(images, sample_arc)\n",
        "        val_acc = torch.mean((torch.max(pred, 1)[1] == labels).type(torch.float))\n",
        "        val_accs.append(val_acc.item())\n",
        "\n",
        "        if verbose:\n",
        "            print_arc(sample_arc)\n",
        "            print('val_acc=' + str(val_acc.item()))\n",
        "            print('-' * 80)\n",
        "\n",
        "    best_iter = np.argmax(val_accs)\n",
        "    best_arc = arcs[best_iter]\n",
        "    best_val_acc = val_accs[best_iter]\n",
        "\n",
        "    controller.train()\n",
        "    shared_cnn.train()\n",
        "    return best_arc, best_val_acc\n",
        "\n",
        "def get_eval_accuracy(loader, shared_cnn, sample_arc):\n",
        "    \"\"\"Evaluate a given architecture.\n",
        "    Args:\n",
        "        loader: A single data loader.\n",
        "        shared_cnn: CNN that contains all possible architectures, with shared weights.\n",
        "        sample_arc: The architecture to use for the evaluation.\n",
        "    \n",
        "    Returns:\n",
        "        acc: Average accuracy.\n",
        "    \"\"\"\n",
        "    total = 0.\n",
        "    acc_sum = 0.\n",
        "    for (images, labels) in loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = shared_cnn(images, sample_arc)\n",
        "        acc_sum += torch.sum((torch.max(pred, 1)[1] == labels).type(torch.float))\n",
        "        total += pred.shape[0]\n",
        "\n",
        "    acc = acc_sum / total\n",
        "    return acc.item()\n",
        "\n",
        "def print_arc(sample_arc):\n",
        "    \"\"\"Display a sample architecture in a readable format.\n",
        "    \n",
        "    Args: \n",
        "        sample_arc: The architecture to display.\n",
        "    Returns: Nothing.\n",
        "    \"\"\"\n",
        "    for key, value in sample_arc.items():\n",
        "        if len(value) == 1:\n",
        "            branch_type = value[0].cpu().numpy().tolist()\n",
        "            print('[' + ' '.join(str(n) for n in branch_type) + ']')\n",
        "        else:\n",
        "            branch_type = value[0].cpu().numpy().tolist()\n",
        "            skips = value[1].cpu().numpy().tolist()\n",
        "            print('[' + ' '.join(str(n) for n in (branch_type + skips)) + ']')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FJvZFfq317c"
      },
      "source": [
        "Load MNIST data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7I4-p1hDWMP"
      },
      "source": [
        "def load_datasets():\n",
        "    \"\"\"Create data loaders for the CIFAR-10 dataset.\n",
        "    Returns: Dict containing data loaders.\n",
        "    \"\"\"\n",
        "    normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize])\n",
        "\n",
        "    if args['cutout'] > 0:\n",
        "        train_transform.transforms.append(Cutout(length=args['cutout']))\n",
        "\n",
        "    valid_transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize])\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize])\n",
        "\n",
        "    train_dataset = datasets.CIFAR10(root=args['data_path'],\n",
        "                                     train=True,\n",
        "                                     transform=train_transform,\n",
        "                                     download=True)\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(root=args['data_path'],\n",
        "                                     train=True,\n",
        "                                     transform=valid_transform,\n",
        "                                     download=True)\n",
        "\n",
        "    test_dataset = datasets.CIFAR10(root=args['data_path'],\n",
        "                                    train=False,\n",
        "                                    transform=test_transform,\n",
        "                                    download=True)\n",
        "\n",
        "    train_indices = list(range(0, 45000))\n",
        "    valid_indices = list(range(45000, 50000))\n",
        "    train_subset = Subset(train_dataset, train_indices)\n",
        "    valid_subset = Subset(valid_dataset, valid_indices)\n",
        "\n",
        "    data_loaders = {}\n",
        "    data_loaders['train_subset'] = torch.utils.data.DataLoader(dataset=train_subset,\n",
        "                                                               batch_size=args['batch_size'],\n",
        "                                                               shuffle=True,\n",
        "                                                               pin_memory=True,\n",
        "                                                               num_workers=2)\n",
        "\n",
        "    data_loaders['valid_subset'] = torch.utils.data.DataLoader(dataset=valid_subset,\n",
        "                                                               batch_size=args['batch_size'],\n",
        "                                                               shuffle=True,\n",
        "                                                               pin_memory=True,\n",
        "                                                               num_workers=2,\n",
        "                                                               drop_last=True)\n",
        "\n",
        "    data_loaders['train_dataset'] = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                                                batch_size=args['batch_size'],\n",
        "                                                                shuffle=True,\n",
        "                                                                pin_memory=True,\n",
        "                                                                num_workers=2)\n",
        "\n",
        "    data_loaders['test_dataset'] = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                                               batch_size=args['batch_size'],\n",
        "                                                               shuffle=False,\n",
        "                                                               pin_memory=True,\n",
        "                                                               num_workers=2)\n",
        "\n",
        "    return data_loaders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Bv3vVmrI43I"
      },
      "source": [
        "Set seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD0-hX_1I3iR"
      },
      "source": [
        "np.random.seed(args['seed'])\n",
        "torch.cuda.manual_seed(args['seed'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTxK1cI2JAKg"
      },
      "source": [
        "# if args['fixed_arc']:\n",
        "#     sys.stdout = Logger(filename='logs/' + args['output_filename'] + '_fixed.log')\n",
        "# else:\n",
        "#     sys.stdout = Logger(filename='logs/' + args['output_filename'] + '.log')\n",
        "\n",
        "print(\"\\n\".join(\"{}\\t{}\".format(k, v) for k, v in args.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfyaFTpaJNNs"
      },
      "source": [
        "Create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dobnh0zJPij"
      },
      "source": [
        "data_loaders = load_datasets()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avV0HGpdJYgM"
      },
      "source": [
        "Create controller"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXiDwYg0JZc3"
      },
      "source": [
        "controller = Controller(search_for=args['search_for'],\n",
        "                        search_whole_channels=True,\n",
        "                        num_layers=args['child_num_layers'],\n",
        "                        num_branches=args['child_num_branches'],\n",
        "                        out_filters=args['child_out_filters'],\n",
        "                        lstm_size=args['controller_lstm_size'],\n",
        "                        lstm_num_layers=args['controller_lstm_num_layers'],\n",
        "                        tanh_constant=args['controller_tanh_constant'],\n",
        "                        temperature=None,\n",
        "                        skip_target=args['controller_skip_target'],\n",
        "                        skip_weight=args['controller_skip_weight'])\n",
        "controller = controller.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhZlPRnrJkkW"
      },
      "source": [
        "Child architectures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmVCQs_FJmCO"
      },
      "source": [
        "shared_cnn = SharedCNN(num_layers=args['child_num_layers'],\n",
        "                        num_branches=args['child_num_branches'],\n",
        "                        out_filters=args['child_out_filters'],\n",
        "                        keep_prob=args['child_keep_prob'])\n",
        "\n",
        "shared_cnn = shared_cnn.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOj77sM0Jqir"
      },
      "source": [
        "Adam optimizer for controller"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1asLfjtKJtgm"
      },
      "source": [
        "# https://github.com/melodyguan/enas/blob/master/src/utils.py#L218\n",
        "controller_optimizer = torch.optim.Adam(params=controller.parameters(),\n",
        "                                        lr=args['controller_lr'],\n",
        "                                        betas=(0.0, 0.999),\n",
        "                                        eps=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGPgqYrGJvcE"
      },
      "source": [
        "SGD optimizer for childs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQBax3GCJwcZ"
      },
      "source": [
        "# https://github.com/melodyguan/enas/blob/master/src/utils.py#L213\n",
        "shared_cnn_optimizer = torch.optim.SGD(params=shared_cnn.parameters(),\n",
        "                                        lr=args['child_lr_max'],\n",
        "                                        momentum=0.9,\n",
        "                                        nesterov=True,\n",
        "                                        weight_decay=args['child_l2_reg'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J0DFh-8J5k9"
      },
      "source": [
        "Child learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvopQ46xKDgz"
      },
      "source": [
        "# https://github.com/melodyguan/enas/blob/master/src/utils.py#L154\n",
        "shared_cnn_scheduler = CosineAnnealingLR(optimizer=shared_cnn_optimizer,\n",
        "                                          T_max=args['child_lr_T'],\n",
        "                                          eta_min=args['child_lr_min'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV4UbRGF_VNp"
      },
      "source": [
        "if args['resume']:\n",
        "    if os.path.isfile(args['resume']):\n",
        "        print(\"Loading checkpoint '{}'\".format(args['resume']))\n",
        "        checkpoint = torch.load(args['resume'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        # args = checkpoint['args']\n",
        "        print(checkpoint.keys())\n",
        "        shared_cnn.load_state_dict(checkpoint['shared_cnn_state_dict'])\n",
        "        controller.load_state_dict(checkpoint['controller_state_dict'])\n",
        "        shared_cnn_optimizer.load_state_dict(checkpoint['shared_cnn_optimizer'])\n",
        "        controller_optimizer.load_state_dict(checkpoint['controller_optimizer'])\n",
        "        shared_cnn_scheduler.optimizer = shared_cnn_optimizer  # Not sure if this actually works\n",
        "        print(\"Loaded checkpoint '{}' (epoch {})\"\n",
        "              .format(args['resume'], checkpoint['epoch']))\n",
        "    else:\n",
        "        raise ValueError(\"No checkpoint found at '{}'\".format(args['resume']))\n",
        "else:\n",
        "  start_epoch = 0\n",
        "\n",
        "if not args['fixed_arc']:\n",
        "    train_enas(start_epoch,\n",
        "                controller,\n",
        "                shared_cnn,\n",
        "                data_loaders,\n",
        "                shared_cnn_optimizer,\n",
        "                controller_optimizer,\n",
        "                shared_cnn_scheduler)\n",
        "else:\n",
        "    assert args['resume'] != '', 'A pretrained model should be used when training a fixed architecture.'\n",
        "    train_fixed(start_epoch,\n",
        "                controller,\n",
        "                shared_cnn,\n",
        "                data_loaders)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}